{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Projection + Logistic Regression Pipeline  (v1)\n",
    "\n",
    "### Introduction:\n",
    "This example uses Scikit-learn's pipeline class to describe a typical machine learning pipeline. Each stage is accelerated using separate FPGA function calls. This means our hardware architecture contains separate Random Projection and Logistic Regression cores, each with their own AXI interfaces and API. This is better illustrated below:\n",
    "\n",
    "<img src=\"imgs/pipe_multi.jpg\">\n",
    "\n",
    "**Note:** This notebook is only compatible with \"multi.bit\" or \"multi_sg.bit\" bitstreams. In addition, the Random Projection stage only supports problems with **n_features=128** and **n_components=32**, and the Logistic Regression stage only supports problems with **n_features=32** and **n_classes=10**. For different problem shapes/sizes, new hybrid libraries should be developed (bitstream + C API + python API). \n",
    "\n",
    "In (v2) we present a notebook which deploys a real hardware pipeline, i.e. one which avoids PL to PS transfers between pipeline stages.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples=5000, n_features=128, centers=10, cluster_std=8, random_state=43)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import pipeline\n",
    "from pynq_sklearn.linear_model import PynqLogisticRegression\n",
    "from pynq_sklearn.random_projection import PynqBinaryRandomProjection\n",
    "\n",
    "rp_sw = PynqBinaryRandomProjection(hw_accel=False)  \n",
    "lr_sw = PynqLogisticRegression(fit_intercept=True, hw_accel=False) \n",
    "\n",
    "sw_pipe = pipeline.Pipeline([(\"dim_red\", rp_sw), (\"clf\", lr_sw)])\n",
    "sw_pipe.fit(X_train, y_train)\n",
    "ypred_sw = sw_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the benchmark\n",
      "Time taken by sw_pipe 200 times 8.112840225000014\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "number=200\n",
    "def swresp():\n",
    "    ypred_sw = sw_pipe.predict(X_test)\n",
    "    return\n",
    "    \n",
    "print(\"Running the benchmark\")\n",
    "sw_time = timeit.timeit(swresp,number=number)\n",
    "print(\"Time taken by sw_pipe\", number,\"times\",sw_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware Pipeline:\n",
    "In a hardware-only pipeline, we deploy both stages' predict/transform to the FPGA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = PynqBinaryRandomProjection(hw_accel=False)\n",
    "lr = PynqLogisticRegression(fit_intercept=True, hw_accel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both accelerators expect 32-bit fixed point numbers (with 20 fractional bits). We make this conversion and also copy the array into physical contiguous memory to avoid expensive virtual address mapping. \n",
    "\n",
    "**Note:** This last step is mandatory for most bitstreams. However, if the bitstream uses SDSoC scatter-gather DMA, the hybrid library will map virtual addresses within the function. This additional overhead hinders system performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC_WIDTH = 20\n",
    "X_test_hw = (X_test*(1<<FRAC_WIDTH)).astype(np.int32)\n",
    "X_test_hw = rp.copy_array(X_test_hw, dtype=np.int32) # allocates X_test_hw to contiguous memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### i.)  fit() is done in software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_pipe = pipeline.Pipeline([(\"dim_red\", rp), (\"clf\", lr)])\n",
    "hw_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ii.) Explicitly set_params so that hw_accel=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_pipe.set_params(dim_red__hw_accel=True, clf__hw_accel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### iii.) Offload transform() and predict() to HW for both PynqBinaryRandomProjection and PynqLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_hw = hw_pipe.predict(X_test_hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### iv.) Verify equivalence\n",
    "We should get approximately the same classification performance. Any errors/differences are attributable to fixed point rounding errors in the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactly equal =\",np.array_equal(ypred_hw , ypred_sw))\n",
    "print(\"Differences =\", np.count_nonzero((ypred_hw - ypred_sw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### v.) Measure the pipeline performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=200\n",
    "def hwresp():\n",
    "    out = hw_pipe.predict(X_test_hw)\n",
    "    return\n",
    "    \n",
    "print(\"Running the benchmark\")\n",
    "hw_time = timeit.timeit(hwresp,number=number)\n",
    "print(\"Time taken by hw_pipe\", number,\"times\",hw_time)\n",
    "print(\"HW Speedup = %.2fx\"%(sw_time/hw_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software/Hardware Pipeline\n",
    "This variation only deploys PynqLogisticRegression predict to the FPGA. PynqRandomProjection is implemented entirely in software. This only works for \"multi_sg.bit\". This bitstream/library uses scatter gather DMA for transferring the input data from PS to PL. This means we don't have to explicitly copy the numpy array into physical contiguous memory.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### i.) Explicitly set_params so that hw_accel=True only for Logistic Regression accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_pipe.set_params(dim_red__hw_accel=False, clf__hw_accel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ii.) Predict\n",
    "Calling predict will only offload PynqLinearRegression to HW. Given that PynqBinaryRandomProjection is stage1 and is computed in SW, the input must be floating point, and is non-contiguous. The output of stage1 is converted to fixed point before stage2. This conversion significantly reduces the pipelines performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_swhw = hw_pipe.predict(X_test)\n",
    "print(\"Exactly equal =\",np.array_equal(ypred_swhw , ypred_sw))\n",
    "print(\"Differences =\", np.count_nonzero((ypred_swhw - ypred_sw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### v.) Measure the sw/hw pipeline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=200\n",
    "def swhwresp():\n",
    "    out = hw_pipe.predict(X_test)\n",
    "    return\n",
    "    \n",
    "print(\"Running the benchmark\")\n",
    "swhw_time = timeit.timeit(hwresp,number=number)\n",
    "print(\"Time taken by swhw_pipe\", number,\"times\",swhw_time)\n",
    "print(\"SW/HW Slowdown = %.2fx\"%(swhw_time/hw_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Classification Results\n",
    "We have access to Scikit-learn's entire library for evaluating and scoring machine learning models. We can perform score() directly on our HW accelerator model, or we can create a custom scoring function to be used separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_pipe.set_params(dim_red__hw_accel=True, clf__hw_accel=True)\n",
    "auc = hw_pipe.score(X_test_hw, y_test) \n",
    "print(\"AUC =\", auc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def custom_scorer(y, y_pred):\n",
    "    # We can put anything in here.\n",
    "    class_names = [\"Class%d\"%(i) for i in range(10)]\n",
    "    return classification_report(y, y_pred, target_names=class_names)\n",
    "\n",
    "print( custom_scorer(y_test, ypred_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html) for classification report details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are finsished, we should free all CMA buffers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.xlnk.xlnk_reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
