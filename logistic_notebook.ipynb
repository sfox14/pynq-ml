{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on PYNQ-Z1\n",
    "### Introduction:\n",
    "\n",
    "This example considers Scikit-Learn's Logistic Regression for linear classification. You will see that a speedup can be achieved by offloading decision_function(x), which contains the main computation, to a custom-built FPGA accelerator running on PYNQ-Z1. We use the PynqLogisticRegression class (in pynq_sklearn/linear_model/linear_classification.py) to load a hybrid library, which contains the bitstream and low-level C API. This class inherits from sklearn.linear_model.LogisticRegression and overrides decision_function(x) when hw_accel=True.\n",
    "\n",
    "**Note:** PynqLogisticRegression wraps an application accelerator for fixed input/output/parameter sizes (i.e. unlike an overlay - it is not customisable post bitstream for different problem shapes/sizes). Our accelerator only supports problems with **n_features=32** and **n_classes=10**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware Accelerator:\n",
    "\n",
    "For prediction, Logistic Regression calls \"decision_function(x)\" which is a simple linear function given here:\n",
    "### $$y(x) = A\\textbf{x} + b$$\n",
    "\n",
    "-  x - input array (n_samples, n_features)<br>\n",
    "-  y - output array (n_samples,)<br>\n",
    "-  A - weight matrix (n_features, n_classes) <br>\n",
    "-  b - offset (n_classes,)<br>\n",
    "\n",
    "<img src=\"imgs/decision_function.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset:\n",
    "We generate a dataset with **n_features=32** and **n_classes=10**, and plot our training set clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import time\n",
    "\n",
    "# Generate dataset of Ints\n",
    "X, y = datasets.make_blobs(n_samples=5000, n_features=32, centers=10, cluster_std=8, random_state=43)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the dataset, we use TSNE to project points from a high-dimensional space (n_features=32) to a 2D plane. Here, we can see 10 distinct clusters/classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X = tsne.fit_transform(X_train[:100])\n",
    "Y = y_train[:100]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Training Set Clusters, n_classes=10\")\n",
    "\n",
    "# Plot also the training points\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, 10))\n",
    "for i, color in zip(np.arange(10), colors):\n",
    "    idx = np.where(Y == i)\n",
    "    plt.scatter(X[idx, 0], X[idx, 1], c=color,\n",
    "                edgecolor='black', s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PYNQ Logistic Regression:\n",
    "Here we will demonstrate a typical machine learning flow for training a model in software and deploying in hardware. We combine the productivity of the entire Scikit-learn ecosystem with the performance of custom hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Fit a Logistic Regression model\n",
    "We import the PynqLogisticRegression model. This class inherits all the functionality of Scikit-learn's LogisticRegression class, and can optionally deploy a fitted model on the PYNQ-Z1 FPGA.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq_sklearn.linear_model import PynqLogisticRegression\n",
    "\n",
    "model = PynqLogisticRegression(fit_intercept=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. FPGA compatible copy of X_test\n",
    "Our FPGA accelerator expects 32-bit fixed point numbers (with 20 fractional bits). We also copy the array into physical contiguous memory to avoid expensive virtual address mapping. \n",
    "\n",
    "**Note:** This last step is mandatory for bitstreams that assume the input is physical contiguous. For bitstreams which use the scatter-gather DMA, the hybrid library will map virtual addresses within the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC_WIDTH = 20\n",
    "X_test_hw = (X_test*(1<<FRAC_WIDTH)).astype(np.int32)\n",
    "X_test_hw = model.copy_array(X_test_hw, dtype=np.int32) # allocates X_test_hw to contiguous memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. With hw_accel=True, deploy prediction on the FPGA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hw_accel = True\n",
    "y_pred = model.predict(X_test_hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Alternatively, deploy in SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hw_accel=False\n",
    "y_pred_sw = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Verify equivalence\n",
    "We should get approximately the same classification performance. Any errors/differences are attributable to fixed point rounding errors in the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Exactly equal =\",np.array_equal(y_pred,y_pred_sw))\n",
    "print(\"Differences =\", np.count_nonzero((y_pred-y_pred_sw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Evaluate the results\n",
    "We have access to Scikit-learn's entire library for evaluating and scoring machine learning models. We can perform score directly on our HW accelerator model, or we can create a custom scoring function to be used separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hw_accel=True\n",
    "auc = model.score(X_test_hw, y_test) \n",
    "print(\"AUC =\", auc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def custom_scorer(y, y_pred):\n",
    "    # We can put anything in here.\n",
    "    class_names = [\"Class%d\"%(i) for i in range(10)]\n",
    "    return classification_report(y, y_pred, target_names=class_names)\n",
    "\n",
    "print( custom_scorer(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html) for classification report details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Performance Comparison\n",
    "Using the FPGA, we can observe a small speedup over a software-only implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "number=200\n",
    "\n",
    "model.hw_accel=True\n",
    "def hwresp():\n",
    "    y=model.predict(X_test_hw)\n",
    "    return\n",
    "\n",
    "hw_time = timeit.timeit(hwresp,number=number)\n",
    "\n",
    "model.hw_accel=False\n",
    "def swresp():\n",
    "    y=model.predict(X_test)\n",
    "    return\n",
    "\n",
    "sw_time = timeit.timeit(swresp,number=number)\n",
    "\n",
    "print(\"Time taken by sklearn\", number,\"times\",sw_time)\n",
    "print(\"Time taken by sklearn+fpga\", number,\"times\",hw_time)\n",
    "print(\"HW Speedup = %.2fx\"%(sw_time/hw_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we only compare the accelerated function (i.e. model.decision_function) then we can observe an even better speedup. This occurs because model.predict() includes additional operations for separating regression results into classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "number=200\n",
    "\n",
    "model.hw_accel=True\n",
    "def hwresp():\n",
    "    y=model.decision_function(X_test_hw)\n",
    "    return\n",
    "\n",
    "hw_time = timeit.timeit(hwresp,number=number)\n",
    "\n",
    "model.hw_accel=False\n",
    "def swresp():\n",
    "    y=model.decision_function(X_test)\n",
    "    return\n",
    "\n",
    "sw_time = timeit.timeit(swresp,number=number)\n",
    "\n",
    "print(\"Time taken by sklearn\", number,\"times\",sw_time)\n",
    "print(\"Time taken by sklearn+fpga\", number,\"times\",hw_time)\n",
    "print(\"HW Speedup = %.2fx\"%(sw_time/hw_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Reset\n",
    "It is good practise to free all CMA buffers when we are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.xlnk.xlnk_reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
