{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Projection + Logistic Regression Pipeline  (v2)\n",
    "\n",
    "### Introduction:\n",
    "This example uses Scikit-learn's pipeline class to describe a machine learning pipeline. In software, this class chains multiple estimators together and executes them sequentially. In hardware this corresponds to sending data from PS to PL and then from PL to PS for each stage in the pipeline. This might be flexible (see v1 notebook) but for optimal performance we should keep the pipeline's state in local FPGA memory and avoid expensive DRAM transfers between stages.  \n",
    "\n",
    "We achieve this using set_params() to explicitly:\n",
    "    -  Offload all computation to stage 1 only, while bypassing HW offload in all other stages\n",
    "    -  Transfer all HW parameters to stage 1\n",
    "\n",
    "<img src=\"imgs/pipe_hw.jpg\">\n",
    "\n",
    "**Note:** This notebook is only compatible with \"pipe.bit\" or \"pipe_sg.bit\" bitstreams. In addition, the Random Projection stage only supports problems with **n_features=128** and **n_components=32**, and the Logistic Regression stage only supports problems with **n_features=32** and **n_classes=10**. For different problem shapes/sizes, new hybrid libraries should be developed (bitstream + C API + python API). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridLibrary(): {'bitstream': 'pipe.bit', 'library': 'libpipe.so', 'dma_sg': False, 'pipe': True, 'c_callable': ' void _p0_Pipe_1_noasync(int *x, int a[320], int b[10], int *output, int datalen); ', 'input_width': 128, 'output_width': 10}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pynq_sklearn import HybridLibrary, Registry\n",
    "\n",
    "lib = Registry.load(\"pipe\")\n",
    "print(lib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples=5000, n_features=128, centers=10, cluster_std=8, random_state=43)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from pynq_sklearn.linear_model import PynqLogisticRegression\n",
    "from pynq_sklearn.random_projection import PynqBinaryRandomProjection\n",
    "\n",
    "rp = PynqBinaryRandomProjection(hw=lib, hw_accel=False)  \n",
    "lr = PynqLogisticRegression(hw=lib, fit_intercept=True, hw_accel=False) \n",
    "\n",
    "ml_pipe = pipeline.Pipeline([(\"dr\", rp), (\"clf\", lr)])\n",
    "ml_pipe = ml_pipe.fit(X_train, y_train)\n",
    "ypred_sw = ml_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the benchmark\n",
      "Time taken by sw_pipe 200 times 8.027412722999998\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "number=200\n",
    "def swresp():\n",
    "    out = ml_pipe.predict(X_test)\n",
    "    return\n",
    "    \n",
    "print(\"Running the benchmark\")\n",
    "sw_time = timeit.timeit(swresp,number=number)\n",
    "print(\"Time taken by sw_pipe\", number,\"times\",sw_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware Pipeline:\n",
    "Both stages' predict/transform methods are executed on the FPGA. Also, both accelerators expect 32-bit fixed point numbers (with 20 fractional bits). We make this conversion and also copy the array into physical contiguous memory. \n",
    "\n",
    "**Note:** This last step is mandatory for most bitstreams. However, if the bitstream uses SDSoC scatter-gather DMA, the hybrid library will perform the necessary virtual address mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC_WIDTH = 20\n",
    "X_test_hw = (X_test*(1<<FRAC_WIDTH)).astype(np.int32)\n",
    "X_test_hw = rp.copy_array(X_test_hw, dtype=np.int32) # allocates X_test_hw to contiguous memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### i.) Explicitly set_params() and configure the HW pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1: \t PynqBinaryRandomProjection\n",
      "sw bypass: \t PynqLogisticRegression\n"
     ]
    }
   ],
   "source": [
    "pipe_params = {\"a\":lr.coef_hw.pointer, \"b\":lr.intercept_hw.pointer, \"n_out\":lr.n_classes}\n",
    "\n",
    "ml_pipe = ml_pipe.set_params(dr__hw_accel=True,\n",
    "                             dr__pipe_params=pipe_params,\n",
    "                             clf__hw_accel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we run predict() on hw_pipe, we will invoke the pipeline from PynqBinaryRandomProjection.transform() method. PynqLogisticRegression.predict() will be bypassed. The only caveat is that the fitted parameters from PynqLogisticRegression must be passed as paramters to PynqBinaryRandomProjection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_hw = ml_pipe.predict(X_test_hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### iv.) Verify equivalence\n",
    "We should get approximately the same classification performance. Any errors/differences are attributable to fixed point rounding errors in the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactly equal = True\n",
      "Differences = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Exactly equal =\",np.array_equal(ypred_hw , ypred_sw))\n",
    "print(\"Differences =\", np.count_nonzero((ypred_hw - ypred_sw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### v.) Measure the pipeline performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the benchmark\n",
      "Time taken by hw_pipe 200 times 0.6482782940001925\n",
      "HW Speedup = 12.38x\n"
     ]
    }
   ],
   "source": [
    "number=200\n",
    "def hwresp():\n",
    "    out = ml_pipe.predict(X_test_hw)\n",
    "    return\n",
    "    \n",
    "print(\"Running the benchmark\")\n",
    "hw_time = timeit.timeit(hwresp,number=number)\n",
    "print(\"Time taken by hw_pipe\", number,\"times\",hw_time)\n",
    "print(\"HW Speedup = %.2fx\"%(sw_time/hw_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Classification Results\n",
    "We can perform score() directly on HW pipeline, or we can create a custom scoring function which can be applied separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.964\n"
     ]
    }
   ],
   "source": [
    "auc = ml_pipe.score(X_test_hw, y_test) \n",
    "print(\"AUC =\", auc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Class0       0.98      0.95      0.96       100\n",
      "     Class1       0.98      0.93      0.95        88\n",
      "     Class2       0.97      0.99      0.98       109\n",
      "     Class3       0.95      0.95      0.95        93\n",
      "     Class4       0.91      0.99      0.95        96\n",
      "     Class5       1.00      0.97      0.98        91\n",
      "     Class6       0.98      0.99      0.99       118\n",
      "     Class7       0.98      0.96      0.97       107\n",
      "     Class8       0.96      0.94      0.95        94\n",
      "     Class9       0.93      0.96      0.95       104\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def custom_scorer(y, y_pred):\n",
    "    # We can put anything in here.\n",
    "    class_names = [\"Class%d\"%(i) for i in range(10)]\n",
    "    return classification_report(y, y_pred, target_names=class_names)\n",
    "\n",
    "print( custom_scorer(y_test, ypred_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html) for classification report details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are finished, we should free all CMA buffers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.xlnk.xlnk_reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
