{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Projection + Logistic Regression Pipeline  (v1)\n",
    "\n",
    "### Introduction:\n",
    "This example uses Scikit-learn's pipeline class to describe a typical machine learning pipeline. Each stage is accelerated using separate FPGA function calls. This means our hardware architecture contains separate Random Projection and Logistic Regression cores, each with their own AXI interfaces and API. This is better illustrated below:\n",
    "\n",
    "<img src=\"imgs/pipe_multi.jpg\">\n",
    "\n",
    "**Note:** This notebook is only compatible with \"multi.bit\" or \"multi_sg.bit\" bitstreams. In addition, the Random Projection stage only supports problems with **n_features=128** and **n_components=32**, and the Logistic Regression stage only supports problems with **n_features=32** and **n_classes=10**. For different problem shapes/sizes, new hybrid libraries should be developed (bitstream + C API + python API). \n",
    "\n",
    "In (v2) we present a notebook which deploys a real hardware pipeline, i.e. one which avoids PL to PS transfers between pipeline stages.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Library:\n",
    "This example implements two independent accelerators on one FPGA. Although the bitstream is shared, the C drivers and python APIs are not, and therefore, we must invoke a hybrid library for both PynqBinaryRandomProjection and PynqLogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridLibrary(): {'bitstream': 'multi_sg.bit', 'library': 'libmulti_sg.so', 'dma_sg': True, 'pipe': False, 'c_callable': ' void _p0_RandomProjection_1_noasync(int *x, int *output, int datalen); ', 'input_width': 128, 'output_width': 32}\n",
      "HybridLibrary(): {'bitstream': 'multi_sg.bit', 'library': 'libmulti_sg.so', 'dma_sg': True, 'pipe': False, 'c_callable': ' void _p0_LinReg_1_noasync(int *x, int a[320], int b[10], int *output, int datalen); ', 'input_width': 32, 'output_width': 10}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pynq_sklearn import HybridLibrary, Registry\n",
    "\n",
    "rp_lib = Registry.load(\"rp_multi_sg\")\n",
    "lr_lib = Registry.load(\"lr_multi_sg\")\n",
    "print(rp_lib)\n",
    "print(lr_lib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.make_blobs(n_samples=5000, n_features=128, centers=10, cluster_std=8, random_state=43)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import pipeline\n",
    "from pynq_sklearn.linear_model import PynqLogisticRegression\n",
    "from pynq_sklearn.random_projection import PynqBinaryRandomProjection\n",
    "\n",
    "rp = PynqBinaryRandomProjection(hw=rp_lib, hw_accel=False)  \n",
    "lr = PynqLogisticRegression(hw=lr_lib, fit_intercept=True, hw_accel=False) \n",
    "\n",
    "ml_pipe = pipeline.Pipeline([(\"dim_red\", rp), (\"clf\", lr)])\n",
    "ml_pipe.fit(X_train, y_train)\n",
    "ypred_sw = ml_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the benchmark\n",
      "Time taken by sw_pipe 200 times 8.140533167000058\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "number=200\n",
    "def swresp():\n",
    "    out = ml_pipe.predict(X_test)\n",
    "    return\n",
    "    \n",
    "print(\"Running the benchmark\")\n",
    "sw_time = timeit.timeit(swresp,number=number)\n",
    "print(\"Time taken by sw_pipe\", number,\"times\",sw_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardware Pipeline:\n",
    "\n",
    "Here we offload both pipeline stages' predict/transform methods to the FPGA. For this to work, we must first convert the input into 32-bit fixed point numbers (with 20 fractional bits), which is compatible with our bitstream. We also copy the input array into physical contiguous memory to avoid expensive virtual address mapping.\n",
    "\n",
    "**Note:** This last step is mandatory for most bitstreams. However, if the bitstream uses SDSoC scatter-gather DMA, the hybrid library will map the virtual addresses to physical memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAC_WIDTH = 20\n",
    "X_test_hw = (X_test*(1<<FRAC_WIDTH)).astype(np.int32)\n",
    "X_test_hw = rp.copy_array(X_test_hw, dtype=np.int32) # allocates X_test_hw to contiguous memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### i.) Explicitly set_params so that hw_accel=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipe = ml_pipe.set_params(dim_red__hw_accel=True, clf__hw_accel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### iii.) Offload transform() and predict() to HW for both PynqBinaryRandomProjection and PynqLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_hw = ml_pipe.predict(X_test_hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### iv.) Verify equivalence\n",
    "We should get approximately the same classification performance. Any errors/differences are attributable to fixed point rounding errors in the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactly equal = True\n",
      "Differences = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Exactly equal =\",np.array_equal(ypred_hw , ypred_sw))\n",
    "print(\"Differences =\", np.count_nonzero((ypred_hw - ypred_sw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### v.) Measure the pipeline performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the benchmark\n",
      "Time taken by hw_pipe 200 times 0.8567619710000827\n",
      "HW Speedup = 9.50x\n"
     ]
    }
   ],
   "source": [
    "number=200\n",
    "def hwresp():\n",
    "    out = ml_pipe.predict(X_test_hw)\n",
    "    return\n",
    "    \n",
    "print(\"Running the benchmark\")\n",
    "hw_time = timeit.timeit(hwresp,number=number)\n",
    "print(\"Time taken by hw_pipe\", number,\"times\",hw_time)\n",
    "print(\"HW Speedup = %.2fx\"%(sw_time/hw_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software/Hardware Pipeline\n",
    "This variation only deploys PynqLogisticRegression predict to the FPGA. PynqRandomProjection is implemented entirely in software. This only works for **\"multi_sg.bit\"**. This bitstream/library uses scatter gather DMA for transferring the input data from PS to PL. This means we don't have to explicitly copy the numpy array into physical contiguous memory.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### i.) Explicitly set_params so that hw_accel=True only for Logistic Regression accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipe = ml_pipe.set_params(dim_red__hw_accel=False, clf__hw_accel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ii.) Predict\n",
    "Calling predict will only offload PynqLinearRegression to HW. Given that PynqBinaryRandomProjection is stage1 and is computed in SW, the input must be floating point, and is non-contiguous. The output of stage1 is converted to fixed point before stage2. This conversion significantly reduces the pipeline's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactly equal = True\n",
      "Differences = 0\n"
     ]
    }
   ],
   "source": [
    "ypred_swhw = ml_pipe.predict(X_test)\n",
    "print(\"Exactly equal =\",np.array_equal(ypred_swhw , ypred_sw))\n",
    "print(\"Differences =\", np.count_nonzero((ypred_swhw - ypred_sw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### v.) Measure the sw/hw pipeline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the benchmark\n",
      "Time taken by swhw_pipe 200 times 10.605611722999924\n",
      "SW/HW Slowdown = 12.38x\n"
     ]
    }
   ],
   "source": [
    "number=200\n",
    "def swhwresp():\n",
    "    out = ml_pipe.predict(X_test)\n",
    "    return\n",
    "    \n",
    "print(\"Running the benchmark\")\n",
    "swhw_time = timeit.timeit(hwresp,number=number)\n",
    "print(\"Time taken by swhw_pipe\", number,\"times\",swhw_time)\n",
    "print(\"SW/HW Slowdown = %.2fx\"%(swhw_time/hw_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Classification Results\n",
    "We have access to Scikit-learn's entire library for evaluating and scoring machine learning models. We can perform score() directly on our HW accelerator model, or we can create a custom scoring function to be used separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy = 0.964\n"
     ]
    }
   ],
   "source": [
    "ml_pipe.set_params(dim_red__hw_accel=True, clf__hw_accel=True)\n",
    "acc = ml_pipe.score(X_test_hw, y_test) \n",
    "print(\"Mean Accuracy =\", acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Class0       0.98      0.95      0.96       100\n",
      "     Class1       0.98      0.93      0.95        88\n",
      "     Class2       0.97      0.99      0.98       109\n",
      "     Class3       0.95      0.95      0.95        93\n",
      "     Class4       0.91      0.99      0.95        96\n",
      "     Class5       1.00      0.97      0.98        91\n",
      "     Class6       0.98      0.99      0.99       118\n",
      "     Class7       0.98      0.96      0.97       107\n",
      "     Class8       0.96      0.94      0.95        94\n",
      "     Class9       0.93      0.96      0.95       104\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def custom_scorer(y, y_pred):\n",
    "    # We can put anything in here.\n",
    "    class_names = [\"Class%d\"%(i) for i in range(10)]\n",
    "    return classification_report(y, y_pred, target_names=class_names)\n",
    "\n",
    "print( custom_scorer(y_test, ypred_sw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html) for classification report details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are finsished, we should free all CMA buffers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.xlnk.xlnk_reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
